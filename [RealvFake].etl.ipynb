{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3baa4d5-b64a-463b-9669-de3d5abbb7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f21f19-4e31-4652-9d20-5871b64e22a0",
   "metadata": {},
   "source": [
    "We'll load our data into Spark for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44e76069-d171-4f17-979d-0ddca2df34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=SparkSession.builder.getOrCreate()\n",
    "\n",
    "DF_True=sc.read.csv('True.csv',header=True,inferSchema=True)\n",
    "DF_Fake=sc.read.csv('Fake.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9058b010-3b30-4bdd-8a24-5e1f0c0fb71c",
   "metadata": {},
   "source": [
    "Add 'Truthness' column--flagging the value of the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbf2f868-df7f-4cf5-9aa9-36b796deb1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+------------------+---------+\n",
      "|               title|                text|     subject|              date|Truthness|\n",
      "+--------------------+--------------------+------------+------------------+---------+\n",
      "|As U.S. budget fi...|WASHINGTON (Reute...|politicsNews|December 31, 2017 |      1.0|\n",
      "|U.S. military to ...|WASHINGTON (Reute...|politicsNews|December 29, 2017 |      1.0|\n",
      "|Senior U.S. Repub...|WASHINGTON (Reute...|politicsNews|December 31, 2017 |      1.0|\n",
      "|FBI Russia probe ...|WASHINGTON (Reute...|politicsNews|December 30, 2017 |      1.0|\n",
      "|Trump wants Posta...|SEATTLE/WASHINGTO...|politicsNews|December 29, 2017 |      1.0|\n",
      "+--------------------+--------------------+------------+------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+--------------------+-------+-----------------+---------+\n",
      "|               title|                text|subject|             date|Truthness|\n",
      "+--------------------+--------------------+-------+-----------------+---------+\n",
      "| Donald Trump Sen...|Donald Trump just...|   News|December 31, 2017|      0.0|\n",
      "| Drunk Bragging T...|House Intelligenc...|   News|December 31, 2017|      0.0|\n",
      "| Sheriff David Cl...|On Friday, it was...|   News|December 30, 2017|      0.0|\n",
      "| Trump Is So Obse...|On Christmas day,...|   News|December 29, 2017|      0.0|\n",
      "| Pope Francis Jus...|Pope Francis used...|   News|December 25, 2017|      0.0|\n",
      "+--------------------+--------------------+-------+-----------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF_True=DF_True.withColumn('Truthness',lit(1.0))\n",
    "DF_Fake=DF_Fake.withColumn('Truthness',lit(0.0))\n",
    "DF_True.show(5)\n",
    "DF_Fake.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9673b0b5-9499-416d-9db1-0c5170ee5119",
   "metadata": {},
   "source": [
    "Combine into single dataframe, remove rows with '\"' as title (since their rows are null also), and replace remaining null values with empty strings.\n",
    "\n",
    "Restrict to 'title', 'text', and 'Truthness' columns, since we decided to remove 'subject' and 'date' for bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "548a9b0a-2033-49ec-824e-c0ebf15b959f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+\n",
      "|               title|                text|Truthness|\n",
      "+--------------------+--------------------+---------+\n",
      "|Connecticut attor...|WASHINGTON (Reute...|      1.0|\n",
      "|\"Collins says Sen...|WASHINGTON (Reute...|      1.0|\n",
      "|Factbox: Republic...|(Reuters) - After...|      1.0|\n",
      "|No new U.S. admin...|WASHINGTON (Reute...|      1.0|\n",
      "|Republican foreig...|WASHINGTON (Reute...|      1.0|\n",
      "|Crime, casualties...|KUNDUZ, Afghanist...|      1.0|\n",
      "|Congo sets presid...|KINSHASA, (Reuter...|      1.0|\n",
      "|Rescue efforts en...|MUMBAI (Reuters) ...|      1.0|\n",
      "| Kushner: I Lied ...|Donald Trump s so...|      0.0|\n",
      "| Dr. Drew: Trump ...|Dr. Drew Pinsky k...|      0.0|\n",
      "| Paul Ryan Though...|House Speaker Pau...|      0.0|\n",
      "| Watch Dan Savage...|Ann Coulter is on...|      0.0|\n",
      "|MUSLIM ASSIMILATI...|This is a story i...|      0.0|\n",
      "|BUCKLE UP: 2008 W...|A fake economy ca...|      0.0|\n",
      "|OOPSâ€¦CDC EMPLOYEE...|I guess we re not...|      0.0|\n",
      "|WATCH TRUMP Call ...|In a press confer...|      0.0|\n",
      "+--------------------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF=DF_True.union(DF_Fake)\n",
    "DF=DF.filter(DF['title']!='\"')\n",
    "DF=DF.fillna('')\n",
    "DF=DF.select(['title','text','Truthness'])\n",
    "DF.sample(False,.0002).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672d013a-6348-4052-a8a7-2f6a0d3b916a",
   "metadata": {},
   "source": [
    "Tokenize and remove filteredwords below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2f65c3b-233c-4a8c-a4da-e63ee831e4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredwords = [\"(Reuters)\",\"-\",\"Trump's\",'\"I','\"The','\"We']\n",
    "\n",
    "titleTokenizer = RegexTokenizer(inputCol='title', outputCol='title_token')\n",
    "textTokenizer = RegexTokenizer(inputCol='text', outputCol='text_token')\n",
    "\n",
    "stopwords = StopWordsRemover(inputCol='text_token', outputCol='textfiltered', stopWords=filteredwords)\n",
    "\n",
    "pipeline_etl = Pipeline(stages=[titleTokenizer,textTokenizer,stopwords])\n",
    "DF = pipeline_etl.fit(DF).transform(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a15447a-e11a-462d-bc60-e0dc97828880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+--------------------+--------------------+--------------------+\n",
      "|               title|                text|Truthness|         title_token|          text_token|        textfiltered|\n",
      "+--------------------+--------------------+---------+--------------------+--------------------+--------------------+\n",
      "|As U.S. budget fi...|WASHINGTON (Reute...|      1.0|[as, u.s., budget...|[washington, (reu...|[washington, the,...|\n",
      "|U.S. military to ...|WASHINGTON (Reute...|      1.0|[u.s., military, ...|[washington, (reu...|[washington, tran...|\n",
      "|Senior U.S. Repub...|WASHINGTON (Reute...|      1.0|[senior, u.s., re...|[washington, (reu...|[washington, the,...|\n",
      "|FBI Russia probe ...|WASHINGTON (Reute...|      1.0|[fbi, russia, pro...|[washington, (reu...|[washington, trum...|\n",
      "|Trump wants Posta...|SEATTLE/WASHINGTO...|      1.0|[trump, wants, po...|[seattle/washingt...|[seattle/washingt...|\n",
      "|White House, Cong...|WEST PALM BEACH, ...|      1.0|[white, house,, c...|[west, palm, beac...|[west, palm, beac...|\n",
      "|Trump says Russia...|WEST PALM BEACH, ...|      1.0|[trump, says, rus...|[west, palm, beac...|[west, palm, beac...|\n",
      "|Factbox: Trump on...|The following sta...|      1.0|[factbox:, trump,...|[the, following, ...|[the, following, ...|\n",
      "|Trump on Twitter ...|The following sta...|      1.0|[trump, on, twitt...|[the, following, ...|[the, following, ...|\n",
      "|Alabama official ...|WASHINGTON (Reute...|      1.0|[alabama, officia...|[washington, (reu...|[washington, alab...|\n",
      "|Jones certified U...|(Reuters) - Alaba...|      1.0|[jones, certified...|[(reuters), -, al...|[alabama, officia...|\n",
      "|New York governor...|NEW YORK/WASHINGT...|      1.0|[new, york, gover...|[new, york/washin...|[new, york/washin...|\n",
      "|Factbox: Trump on...|The following sta...|      1.0|[factbox:, trump,...|[the, following, ...|[the, following, ...|\n",
      "|Trump on Twitter ...|\"The following st...|      1.0|[trump, on, twitt...|[\"the, following,...|[following, state...|\n",
      "|Man says he deliv...| (In Dec. 25 stor...|      1.0|[man, says, he, d...|[(in, dec., 25, s...|[(in, dec., 25, s...|\n",
      "|Virginia official...|(Reuters) - A lot...|      1.0|[virginia, offici...|[(reuters), -, a,...|[a, lottery, draw...|\n",
      "|U.S. lawmakers qu...|WASHINGTON (Reute...|      1.0|[u.s., lawmakers,...|[washington, (reu...|[washington, a, g...|\n",
      "|Trump on Twitter ...|The following sta...|      1.0|[trump, on, twitt...|[the, following, ...|[the, following, ...|\n",
      "|U.S. appeals cour...|(Reuters) - A U.S...|      1.0|[u.s., appeals, c...|[(reuters), -, a,...|[a, u.s., appeals...|\n",
      "|Treasury Secretar...|(Reuters) - A gif...|      1.0|[treasury, secret...|[(reuters), -, a,...|[a, gift-wrapped,...|\n",
      "+--------------------+--------------------+---------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd62bfa5-c7a1-4167-85f6-f92ea9179c9a",
   "metadata": {},
   "source": [
    "Pandas ETL for the neural network:\n",
    "\n",
    "(here we'll just grab the 'text' body and exclude the 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7784a74-28c7-4a67-a00c-5b43e73be43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amonn\\AppData\\Local\\Temp\\ipykernel_18260\\1329905758.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  DF_Pandas['text']=DF_Pandas['text'].str.replace(word,'')\n"
     ]
    }
   ],
   "source": [
    "filteredwords = ['(Reuters)','-',\"Trump's\",'\"I','\"The','\"We']\n",
    "\n",
    "# load, add 'Truthness', concatenate\n",
    "real = pd.read_csv('True.csv')\n",
    "real['Truthness'] = 1\n",
    "fake = pd.read_csv('Fake.csv')\n",
    "fake['Truthness'] = 0\n",
    "DF_Pandas = pd.concat([real,fake])\n",
    "del real,fake\n",
    "\n",
    "# remove filteredwords\n",
    "for word in filteredwords:\n",
    "    DF_Pandas['text']=DF_Pandas['text'].str.replace(word,'')\n",
    "\n",
    "# split data here\n",
    "train, test = train_test_split(DF_Pandas[['text','Truthness']], test_size=0.2, random_state=3)\n",
    "del DF_Pandas\n",
    "\n",
    "# split between text and label\n",
    "train_x = train['text']\n",
    "train_y = train['Truthness']\n",
    "test_x = test['text']\n",
    "test_y = test['Truthness']\n",
    "del train, test\n",
    "\n",
    "# tokenize top words\n",
    "maxwords = 10000\n",
    "tokenizer = Tokenizer(num_words=maxwords, lower=True, split=' ')\n",
    "tokenizer.fit_on_texts(train_x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5a5250-a320-466d-8273-f1285dab5c77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
